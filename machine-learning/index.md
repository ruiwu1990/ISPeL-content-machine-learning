---
layout: default
title: Machine Learning
---
<span class="newthought">Machine Learning</span>


Relevant topics and the dependencies between topics have been identified. The prerequisites for topics have been integrated into the layout of the material so that learners can personalize their path of study within each topic.  

As a guide to the learner, each module below begins with an Introduction that describes the preliminaries for the topic and this is where we suggest that every learner should begin.  {% include sidenote.html id="note-pgm" note="The materials presented are based on the ontology constructed by [Dr. Rui Wu](http://www.cs.ecu.edu/wu/),  [Grayson Blankenship]() and other research members of the ISPeL System Project Team funded by the [NSF](https://www.nsf.gov) as part of the [PPSE](https://ppse.ecu.edu/)" %}


A learner can proceed as they are inclined within the module to create their own path among the topics.   The concepts within the modules are intended to be discovered in any order.  


Machine Learning available topics: 
1. [Introduction](1_intro_part2/)
- [Statistical Learning](1_intro_part2/#statistical-learning)
- [Notation](1_intro_part2/#notation)
- [How to implement f(X)](1_intro_part2/#how-to-implement-f(x)-?)
- [The regression function f(x)](1_intro_part2/part2/#the-regression-function-f(x))
- [How to estimate f](1_intro_part2/part2/#how-to-estimate-f)
- [Curse of Dimensionality](1_intro_part2/part2/#curse-of-dimensionality)
2. [KNN vs K_Means](2_KNN_vs_K_Means/)
- [KNN Steps]()
- [Challanges]()
- [KNN: How]()
- [KNN Advantages vs Disadvantages]()
- [KNN: K changes]()
- [Matplotlib]()
- [K_Means]()
- [K-Means: Advantages vs Disadvantages]()
- [Confusion Matrix]()
- [K-Means: how to find a good K]()
3. [Linear Regression](3_Linear_regression/)
- [Correlation]()
- [Covariance vs Correlation]()
- [Multiple linear regression]()
- [Linear regression]()
- [Overfitting vs Underfitting]()
- [Regularization]()
- [Bias variance tradeoff]()
- [Metrics for evaluation]()
- [ROC Curve]()
- [R^2 Value]()
- [RMSE, MSE and MAE]()
- [Model validation]()
4. [Tree Based Method](5_Tree_Based_Method_Part1/)
- [Important Things of Decision Trees]()
- [Split Attributes]()
- [Measures of performance]()
- [Gini]()
- [Entropy]()
- [Gain]()
- [Decision Tree—An Example]()
5. [Tree Based Method Part2](5_Tree_Based_Method_Part2/)
- [Ensembling]()
- [Bootstrap]()
- [Bagging]()
- [Boosting]()
6. [SVM](6_SVM)
- [Important Things of Decision Trees]()
- [Split Attributes]()
- [Measures of performance]()
- [Gini]()
- [Entropy]()
- [Gain]()
- [Decision Tree—An Example]()
7. [PCA](PCA)
- [PCA Dimensionality Reduction]()
- [PCA Sample Code]()
- [PCA Handwriting Digit]()
8. [GA](GA)
- [Traveling Salesperson Problem]()
- [High Level GA]()
- [GA Workflow]()
- [Crossover]()

<script src="http://d3js.org/d3.v3.min.js"></script>
<script src="script/ontology.js"></script>

<!-- <div id="ontology_div"></div> -->
<!-- <div></div> -->
<body></body>



|||[Index](file path)||| [Prev](file path)|||[Next](file path)|||

|||[Machine Learning](../)|||


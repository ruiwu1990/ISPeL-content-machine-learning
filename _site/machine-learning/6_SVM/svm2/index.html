<!DOCTYPE html>
<html>
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>SVM</title>
  <meta name="description" content="ISPeL is an interactive system for personalization of learning. It uses topic-based authoring.">

  <!---   <link rel="stylesheet" href="/ISPeL-content-machine-learning/css/tufte.css" --->
  <link rel="stylesheet" href="../../../css/tufte.css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'><!-- Load up MathJax script if needed ... specify in /_data/options.yml file--><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');
  </script>

  <link rel="canonical" href="http://localhost:7000/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/">
  <link rel="alternate" type="application/rss+xml" title="ISPeL-content-machine-learning" href="http://localhost:7000/ISPeL-content-machine-learning/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->


<header>
    <nav class="group">
    <a href="../../../">Machine Learning</a>
    <a href="http://ispel.cs.ecu.edu/" _target="blank">ISPeL</a>
    <a href="http://seng5005.cs.ecu.edu/" _target="blank">Fall 2020</a>
    <a href="https://github.com/vngudivada/ISPeL-content-machine-learning.git" _target="blank">GitHub</a>
    </nav>
</header>

    <article class="group">
      

<h1>Svm</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        E: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Re: "{\\mathbb{R}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h2 id="support-vector-classifiers">Support Vector Classifiers</h2>

<p><label for="SVM" class="margin-toggle">⊕</label>
<input type="checkbox" id="SVM" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/support.png" alt="Sometimes, it is not possible to be perfect.How to define a hyperplane for this case?" /><br />
    Sometimes, it is not possible to be perfect.How to define a hyperplane for this case?
</span></p>

<p><label for="SVM" class="margin-toggle">⊕</label>
<input type="checkbox" id="SVM" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/support2.png" alt="Question: which is hyperplane is better?" /><br />
    Question: which is hyperplane is better?
</span></p>

<p><label for="SVM" class="margin-toggle">⊕</label>
<input type="checkbox" id="SVM" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/support3.png" alt="Figure 1" /><br />
    Figure 1
</span></p>

<p><label for="SVM" class="margin-toggle">⊕</label>
<input type="checkbox" id="SVM" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/epsilon.png" alt="Figure 2" /><br />
    Figure 2
</span></p>

<p><label for="SVM" class="margin-toggle">⊕</label>
<input type="checkbox" id="SVM" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/6_SVM/svm2/c.png" alt="Figure 3" /><br />
    Figure 3
</span></p>

<ul>
  <li>It could be <font color="red">worthwhile to mis-classify</font> a few training observations in order to do a better job in classifying the remaining observations.
    <ul>
      <li>Greater robustness to individual observations</li>
      <li>Better classification of most of the training observations.</li>
    </ul>
  </li>
  <li>Based on ideas above—<font color="red">Support Vector Classifier</font>, aka <font color="red">soft margin classifier</font>.</li>
</ul>

<h3 id="figure-1">Figure 1</h3>
<ul>
  <li>
    <p>Left: A support vector classifier was fit to a small data set. The hyperplane is shown as a solid line and the margins are shown as dashed lines. Purple observations: Observations 3,4,5 and 6 are on the correct side of the margin, observation 2 is on the margin, and observation 1 is on the wrong side of the margin. Blue observations: Observations 7 and 10 are on the correct side of the margin, observation 9 is on the margin, and observation 8 is on the wrong side of the margin. No observations are on the wrong side of the hyperplane. Right: Same as left panel with two additional points, 11 and 12. These two observations are on the wrong side of the hyperplane and the wrong side of the</p>
  </li>
  <li>
    <p>Similar to Maximal Margin Classifier, this is also an optimization problem: Goal–Maximize \(M\)</p>
  </li>
</ul>

\[\sum_{j=1}^p \beta^2_j =1,\]

\[y_i(\beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + ... + \beta_px_{ip}) \geq M(1 - \epsilon_i),\]

\[\epsilon_i  \geq 0,  \sum_{i=1}^n\epsilon_i  \leq C\]

<ul>
  <li>C is a nonnegative tuning parameter; M is the width of the margin; ε1, . . . ,   εn are slack variables that allow individual observations to be on the wrong side of the margin or the hyperplane</li>
</ul>

<h2 id="support-vector-classifiers--ε">Support Vector Classifiers – ε</h2>
<ul>
  <li>If εi = 0 then the ith observation is on the correct side of the margin; If εi &gt; 0 then the ith observation is on the wrong side of the margin, and we say that the ith observation has violated the margin. If εi &gt; 1 then it is on the wrong side of the hyperplane. Figure 2.</li>
</ul>

\[y_i(\beta_0 + \beta_1x_i1 + \beta_2x_i2 + ... + \beta_px_ip) \geq M(1 - \epsilon_i),\]

<h2 id="support-vector-classifiers--c">Support Vector Classifiers – C</h2>
<ul>
  <li><mark>Question: For figure 3, which one has a larger C value for the same dataset?</mark></li>
  <li>If C is large, then there will be low variance (i.e. predication is stable, since many observations are support vectors), but potentially high bias.</li>
  <li>If C is small, then there will be fewer support vectors and hence the resulting classifier will have low bias but high variance.</li>
  <li>How to choose a good “C”?-&gt;Cross-validation. C controls the bias-variance trade-off of the statistical learning technique.</li>
</ul>

\[\epsilon_i  \geq 0,  \sum_{i=1}^n\epsilon_i  \leq C\]

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><a href="../../../">Index</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../">Prev</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../svm3">Next</a></td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>



    </article>
    <footer>
<hr class="slender">
<div class="credits">
This work is supported by the <a href="https://www.nsf.gov/" target="_blank">NSF</a> IUSE/PFE:RED award No. <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730568" target="_blank">1730568</a>. Site created with <a href="//jekyllrb.com" target="_blank">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll" target="_blank">Tufte theme</a>. &copy; 2021
</div>
</footer>
  </body>
</html>

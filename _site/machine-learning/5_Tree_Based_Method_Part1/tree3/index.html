<!DOCTYPE html>
<html>
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Tree Based Method</title>
  <meta name="description" content="ISPeL is an interactive system for personalization of learning. It uses topic-based authoring.">

  <!---   <link rel="stylesheet" href="/ISPeL-content-machine-learning/css/tufte.css" --->
  <link rel="stylesheet" href="../../../css/tufte.css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'><!-- Load up MathJax script if needed ... specify in /_data/options.yml file--><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');
  </script>

  <link rel="canonical" href="http://localhost:7000/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part1/tree3/">
  <link rel="alternate" type="application/rss+xml" title="ISPeL-content-machine-learning" href="http://localhost:7000/ISPeL-content-machine-learning/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->


<header>
    <nav class="group">
    <a href="../../../">Machine Learning</a>
    <a href="http://ispel.cs.ecu.edu/" _target="blank">ISPeL</a>
    <a href="http://seng5005.cs.ecu.edu/" _target="blank">Fall 2020</a>
    <a href="https://github.com/vngudivada/ISPeL-content-machine-learning.git" _target="blank">GitHub</a>
    </nav>
</header>

    <article class="group">
      

<h1>Tree based method</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        E: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Re: "{\\mathbb{R}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h2 id="measures-of-performance">Measures of performance</h2>
<ul>
  <li>Measures of performance? Three usually used methods
    <ul>
      <li>Gini Index: Based on impurity</li>
      <li>Entropy: similar to the Gini Index, is known as the Cross-Entropy or Deviance</li>
      <li>Classification Error Rate: Based on error</li>
    </ul>
  </li>
  <li>Let’s have a closer look at this Gini Index first</li>
</ul>

\[GINI(t)=1- \Sigma {j}[p(j | t)]^2\]

<ul>
  <li>Here t is the node index; j is the class index; j/t represents the proportion of training observations.</li>
  <li>Gini index is a measure of total variance across the K classes (impurity).</li>
  <li>Lower Gini(t) means better.</li>
</ul>

<h3 id="group-work-calculate-gini-index"><font color="red">Group work</font> Calculate Gini Index:</h3>

<p><label for="Tree Based Method" class="margin-toggle">⊕</label>
<input type="checkbox" id="Tree Based Method" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part1/tree3/split.png" alt="Same idea can be applied with categorical attributes. Which is better?" /><br />
    Same idea can be applied with categorical attributes. Which is better?
</span></p>

<p><label for="Tree Based Method" class="margin-toggle">⊕</label>
<input type="checkbox" id="Tree Based Method" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part1/tree3/image3.svg" alt="How to choose thresholds for continuous attributes? We can also use Gini index." /><br />
    How to choose thresholds for continuous attributes? We can also use Gini index.
</span></p>

<p><label for="Tree Based Method" class="margin-toggle">⊕</label>
<input type="checkbox" id="Tree Based Method" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part1/tree3/image4.png" alt="Same idea can be applied with continuous attributes." /><br />
    Same idea can be applied with continuous attributes.
</span></p>

<p><label for="Tree Based Method" class="margin-toggle">⊕</label>
<input type="checkbox" id="Tree Based Method" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part1/tree3/giniIndex.png" alt="SGini Index can also be used for a collection of nodes where ni = number of records at child i, and n = number of records at parent node p. " /><br />
    SGini Index can also be used for a collection of nodes where ni = number of records at child i, and n = number of records at parent node p.</span></p>

<p>&lt;/span&gt;</p>

<h2 id="measures-of-performancegini">Measures of performance—Gini</h2>

\[GINI(t)=1- \Sigma {j}[p(j | t)]^2\]

<p><img src="gini.png" alt="" /></p>

<ul>
  <li>With a split of [0,6]: P(C1) = 0/6 = 0   P(C2) = 6/6 = 1, then Gini([0,6]) = 1 – P(C1)2 – P(C2)2 = 1 – 0 – 1 = 0.000</li>
  <li>With a split of [1,5]: P(C1) = 1/6 and P(C2) = 5/6, then Gini([1,5]) = 1 – (1/6)2 – (5/6)2 = 0.278</li>
  <li>With a split of [2,4]: P(C1) = 1/3 and P(C2) = 2/3, then Gini([2,4]) = 1 – (1/3)2 – (2/3)2 = 0.444</li>
  <li>
    <p>With a split of [3,3: P(C1) = 1/2 and P(C2) = 1/2, then Gini([3,3]) = 1 – (1/2)2 – (1/2)2 = 0.500</p>
  </li>
  <li>Compute impurity measure (P) before splitting</li>
  <li>Compute impurity measure (M) after splitting
    <ul>
      <li>Compute impurity measure of each child node</li>
      <li>M is the weighted impurity of children</li>
    </ul>
  </li>
  <li>Choose the attribute test condition that produces the highest gain: </li>
  <li>Gain = P - M</li>
</ul>

<h2 id="measures-of-performanceentropy">Measures of performance—Entropy</h2>
<ul>
  <li>I know it is still a little bit confusing. Let’s learn what is Entropy and then we will build a tree together.</li>
  <li>Entropy:</li>
</ul>

\[Entropy(t) = - \Sigma_{j}p(j | t)log p(j | t)\]

<ul>
  <li>
    <p>is the entropy for a given node t of class j. That is, p(j / t) is the relative frequency of class j at node t.</p>
  </li>
  <li>
    <font color="red">Maximum</font>
    <p>is <font color="red">log Nc</font> when records are equally distributed among all classes implying least information. Nc is the number of classes. E.g., if you have three <font color="red">classes</font> and 6 records (i.e. the node is like this C0:2, C1:2, C2:2=&gt; -(1/3)log(1/3)-(1/3)log(1/3)-(1/3)log(1/3)), has  maximum is –log(1/3) = 0.477.</p>
  </li>
  <li>
    <font color="red">Minimum</font>
    <p>is 0.0 when all records belong to one class, implying most information, e.g., C0:5, C1:0=&gt; -1<em>log1 – (-infi)</em>0= 0</p>
  </li>
  <li>
    <font color="red">Lower</font>
    <p>Entropy, means <font color="red">better</font></p>
  </li>
</ul>

<h3 id="group-work"><font color="red">Group work</font>:</h3>

<p><img src="image5.png" alt="" /></p>

<ul>
  <li>Log0 = -inif</li>
  <li>With a split of [0,6]: P(C1) = 0/6 = 0   P(C2) = 6/6 = 1, then Entropy([0,6]) = – 0 log 0 – 1 log 1 = – 0 – 0 = 0.000</li>
  <li>With a split of [1,5]: P(C1) = 1/6 and P(C2) = 5/6, then Entropy([1,5]) = – (1/6) log2 (1/6) – (5/6) log2 (1/6) = 0.65</li>
  <li>With a split of [2,4]: P(C1) = 2/6 and P(C2) = 4/6, then Entropy([2,4]) = – (2/6) log2 (2/6) – (4/6) log2 (4/6) = 0.92</li>
  <li>With a split of [3,3: P(C1) = 1/2 and P(C2) = 1/2, then Entropy([3,3]) = – (1/2) log2 (1/2) – (1/2) log2 (1/2) = 1.00</li>
</ul>

<h2 id="measures-of-performancegain">Measures of performance—Gain</h2>

\[GAIN_{split}=Entropy(p)-( \Sigma _{i=1}^{k} \frac{n_i}{n}Entropy(i))\]

<ul>
  <li>Parent Node, p is split into k partitions where ni is number of records in partition i</li>
  <li>Choose the split that achieves most reduction, which maximizes GAIN</li>
  <li>Entropy is used in the ID3 and C4.5 decision tree algorithms.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><a href="../../../">Index</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../">Prev</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../tree4">Next</a></td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>


    </article>
    <footer>
<hr class="slender">
<div class="credits">
This work is supported by the <a href="https://www.nsf.gov/" target="_blank">NSF</a> IUSE/PFE:RED award No. <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730568" target="_blank">1730568</a>. Site created with <a href="//jekyllrb.com" target="_blank">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll" target="_blank">Tufte theme</a>. &copy; 2020
</div>
</footer>
  </body>
</html>

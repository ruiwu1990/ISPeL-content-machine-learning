<!DOCTYPE html>
<html>
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Tree Based Method</title>
  <meta name="description" content="ISPeL is an interactive system for personalization of learning. It uses topic-based authoring.">

  <!---   <link rel="stylesheet" href="/ISPeL-content-machine-learning/css/tufte.css" --->
  <link rel="stylesheet" href="../../css/tufte.css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'><!-- Load up MathJax script if needed ... specify in /_data/options.yml file--><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');
  </script>

  <link rel="canonical" href="http://localhost:7000/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part2/">
  <link rel="alternate" type="application/rss+xml" title="ISPeL-content-machine-learning" href="http://localhost:7000/ISPeL-content-machine-learning/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->


<header>
    <nav class="group">
    <a href="../../">Machine Learning</a>
    <a href="http://ispel.cs.ecu.edu/" _target="blank">ISPeL</a>
    <a href="http://seng5005.cs.ecu.edu/" _target="blank">Fall 2020</a>
    <a href="https://github.com/vngudivada/ISPeL-content-machine-learning.git" _target="blank">GitHub</a>
    </nav>
</header>

    <article class="group">
      

<h1>Tree based method</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        E: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Re: "{\\mathbb{R}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h2 id="ensembling">Ensembling</h2>

<ul>
  <li>We have learned how to build a decision tree. Now, let’s learn how to build a forest: Ensemble method</li>
  <li>Ensemble methods combine several decision trees to produce better predictive performance than a single decision tree. The main principle (assumption) behind the ensemble model is that <mark>a group of weak learners come together to form a strong learner</mark>, thus increasing the accuracy of the model.</li>
  <li>
    <p>Two popular methods: Bagging and Boosting</p>
  </li>
  <li>Based on: <a href="https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/">https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/</a></li>
</ul>

<h2 id="bootstrap-sample">Bootstrap Sample</h2>

<ul>
  <li>But wait a second, we need to learn what is “bootstrap sample” first.</li>
  <li>
    <p>The <font color="red">bootstrap</font> is a fundamental resampling tool in statistics. The basic idea underlying the bootstrap is what we can estimate the true distrubtion by the so-called <font color="red">emperical distribution</font> \(\hat{F}\)</p>
  </li>
  <li>
    <p>A good tutorial about emperical distribution: <a href="https://www.statlect.com/asymptotic-theory/empirical-distribution">https://www.statlect.com/asymptotic-theory/empirical-distribution</a></p>
  </li>
  <li>Replacement: a same data point can be selected multiple times</li>
  <li>A <font color="red">bootstrap sample</font> of size m from the training data is</li>
</ul>

\[(x_i^*,y_i^*), i=1,...m\]

<ul>
  <li>
    <p>where each \((x_i^*,y_i^*)\) are drawn from uniformly at random from \((x_1,y_1),...(x_n,y_n)\), <font color="red">with replacement</font></p>
  </li>
  <li>
    <p>This corresponds exactly to m independent draws from \(\hat{F}\). Hence it approximates what we would see if we could sample more data from the true data distribution. We often consider \(m=0.6*n\).</p>
  </li>
</ul>

<p>Based on: <a href="https://www.stat.cmu.edu/~ryantibs/datamining/lectures/24-bag.pdf">https://www.stat.cmu.edu/~ryantibs/datamining/lectures/24-bag.pdf</a></p>

<h2 id="bagging">Bagging</h2>

<p><label for="Tree Based Method" class="margin-toggle">⊕</label>
<input type="checkbox" id="Tree Based Method" class="margin-toggle" />
<span class="marginnote"><img class="fullwidth" src="/ISPeL-content-machine-learning/machine-learning/5_Tree_Based_Method_Part2/bagging.png" alt="&lt;a name='figure1'&gt;Figure 1&lt;/a&gt; Diagram to show the basic funtionality of bagging and its goal. Figure Credit: &lt;https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/&gt;" /><br />
    <a name="figure1">Figure 1</a> Diagram to show the basic funtionality of bagging and its goal. Figure Credit: <a href="https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/">https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/</a>
</span></p>

<ul>
  <li>Bagging is used when the goal is to <font color="red">reduce the variance</font> of a decision tree classifier. Here the objective is to create several subsets of data from training sample chosen randomly with replacement. Each collection of subset data is used to train their decision trees. <a href="#figure1">Figure 1</a></li>
  <li>
    <font color="red">White Board demo steps</font>
  </li>
  <li>The number of samples in each bag is be less than training dateset and a common ratio is 60%.</li>
  <li>Possible methods to combine results:
    <ul>
      <li>Classification: majority vote</li>
      <li>Regression: mean value</li>
    </ul>
  </li>
  <li>Note: bagging a good classifier can improve predictive accuracy, but bagging a bad one can seriously degrade predictive accuracy</li>
  <li>Advantages:
    <ul>
      <li>Reduces over-fitting of the model.</li>
      <li>Handles higher dimensionality data very well.</li>
    </ul>
  </li>
  <li>Disadvantages:
    <ul>
      <li>Loss of interpretability: final model is a combination of multiple models</li>
      <li>Computational complexity: multiply the work of classification/regression</li>
    </ul>
  </li>
  <li>Based on: <a href="https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/">https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/</a> and <a href="https://www.youtube.com/watch?v=2Mg8QD0F1dQ">https://www.youtube.com/watch?v=2Mg8QD0F1dQ</a></li>
</ul>

<h2 id="sample-code-regression-tree">Sample Code: Regression Tree</h2>

<ul>
  <li>RandomForestClassifier</li>
  <li>Plt.errorbar: this function can be used to show confidence or precision in a set of measurements or calculated values.</li>
</ul>

<h2 id="group-activity-9">Group Activity 9</h2>
<ul>
  <li>Train a random forest classifier</li>
  <li>Find out which features are more important</li>
</ul>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><a href="../../">Index</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../">Prev</a></td>
      <td> </td>
      <td> </td>
      <td><a href="part2-2">Next</a></td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>


    </article>
    <footer>
<hr class="slender">
<div class="credits">
This work is supported by the <a href="https://www.nsf.gov/" target="_blank">NSF</a> IUSE/PFE:RED award No. <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730568" target="_blank">1730568</a>. Site created with <a href="//jekyllrb.com" target="_blank">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll" target="_blank">Tufte theme</a>. &copy; 2020
</div>
</footer>
  </body>
</html>

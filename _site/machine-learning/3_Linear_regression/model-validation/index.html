<!DOCTYPE html>
<html>
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Model Validation</title>
  <meta name="description" content="ISPeL is an interactive system for personalization of learning. It uses topic-based authoring.">

  <!---   <link rel="stylesheet" href="/ISPeL-content-machine-learning/css/tufte.css" --->
  <link rel="stylesheet" href="../../../css/tufte.css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'><!-- Load up MathJax script if needed ... specify in /_data/options.yml file--><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');
  </script>

  <link rel="canonical" href="http://localhost:7000/ISPeL-content-machine-learning/machine-learning/3_Linear_regression/model-validation/">
  <link rel="alternate" type="application/rss+xml" title="ISPeL-content-machine-learning" href="http://localhost:7000/ISPeL-content-machine-learning/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->


<header>
    <nav class="group">
    <a href="../../../">Machine Learning</a>
    <a href="http://ispel.cs.ecu.edu/" _target="blank">ISPeL</a>
    <a href="http://seng5005.cs.ecu.edu/" _target="blank">Fall 2020</a>
    <a href="https://github.com/vngudivada/ISPeL-content-machine-learning.git" _target="blank">GitHub</a>
    </nav>
</header>

    <article class="group">
      

<h1>Model validation</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        E: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Re: "{\\mathbb{R}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<ul>
  <li>Holdout sets for validation: hold back some subset of the training data and this part is called holdout set. Then we use this part data for test.
    <ul>
      <li>What are the possible disadvantages?</li>
    </ul>
  </li>
  <li>Cross-validation: sometimes called rotation estimation or out-of-sample testing, is any of various similar model validation techniques for <font color="red">assessing</font> how the results of a statistical analysis will generalize to an independent data set.</li>
</ul>

<p><img src="folds.png" alt="" /></p>

<ul>
  <li>K-fold cross validation: k is the number of number of sections/folds.</li>
  <li>K-fold cross validation is very useful for model performance estimation and model parameter tuning (HW4).</li>
</ul>

<h2 id="sample-code">Sample Code</h2>
<ul>
  <li>Model Validation</li>
  <li>Accuracy_score: calculate classification accuracy rate, works for multiple classes</li>
  <li>Cross_val_score: automatically split data following cross validation ideas.</li>
</ul>

<p>Source Code: <a href="https://colab.research.google.com/github/ruiwu1990/CSCI_4120/blob/master/Evaluation/Model%20Validation.ipynb">https://colab.research.google.com/github/ruiwu1990/CSCI_4120/blob/master/Evaluation/Model%20Validation.ipynb</a></p>

<h2 id="group-activity-6">Group Activity 6</h2>
<ul>
  <li>Leave One Out: it is still <font color="red">cross validation</font>. Each time, only one element is left for test, i.e. validation set size is always one.</li>
  <li>Leave-one-out cross-validation is approximately <font color="red">unbiased</font>, because the difference in size between the training set used in each fold and the entire dataset is only a single pattern.</li>
  <li>
    <p>It tends to have a <font color="red">high</font> variance (so you would get very different estimates if you repeated the estimate with different initial samples of data from the same distribution).</p>
  </li>
  <li>Source Code: <a href="https://colab.research.google.com/github/ruiwu1990/CSCI_4120/blob/master/Evaluation/Model%20Validation.ipynb">https://colab.research.google.com/github/ruiwu1990/CSCI_4120/blob/master/Evaluation/Model%20Validation.ipynb</a></li>
</ul>

<p><img src="folds.png" alt="" /></p>

<ul>
  <li>Based on: <a href="https://stats.stackexchange.com/questions/154830/10-fold-cross-validation-vs-leave-one-out-cross-validation">https://stats.stackexchange.com/questions/154830/10-fold-cross-validation-vs-leave-one-out-cross-validation</a></li>
</ul>

<h2 id="parameter-tuning">Parameter Tuning</h2>
<ul>
  <li>Grid Search:
    <ul>
      <li>Grid search is an approach to parameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.</li>
      <li>The grid search provided by sklearn.model_selection.GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter. For instance, the following param_grid:</li>
    </ul>
  </li>
</ul>

<p><img src="paraTune.png" alt="" /></p>
<ul>
  <li>Random Search:
    <ul>
      <li>Random search is an approach to parameter tuning that will sample algorithm parameters from a <font color="red">random distribution</font> (i.e. uniform) for a fixed number of iterations. A model is constructed and evaluated for each combination of parameters chosen.</li>
    </ul>
  </li>
  <li>Examples and more details can be found here:</li>
</ul>
<p><a href="https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search">https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search</a></p>

<h2 id="homework-4-group-homework">Homework 4: Group Homework</h2>
<ul>
  <li>Parameter Tuning and Select Best Model</li>
  <li>In Regularization jupyter notebook, we have walked through a bicycle traffic prediction example. You are required to compare “LinearRegression”, “Lasso”, and “Ridge” regression models. Select the best one based on 10-fold cross validation results. Please use the same features (holiday, daylight_hrs …) to predict traffic as shown in the sample code.</li>
  <li>You need to tune alpha for “Lasso” and “Ridge.” To do it, you should use “RandomizedSearchCV” (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html</a>)</li>
  <li>README.MD file
    <ul>
      <li>Team member names and email addresses</li>
      <li>All three models’ cross validation scores and alpha value (if applied)</li>
      <li>Which model performs the best</li>
    </ul>
  </li>
</ul>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td> </td>
      <td><a href="../../">Index</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../metrics-for-evaluation-2/">Prev</a></td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>


    </article>
    <footer>
<hr class="slender">
<div class="credits">
This work is supported by the <a href="https://www.nsf.gov/" target="_blank">NSF</a> IUSE/PFE:RED award No. <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730568" target="_blank">1730568</a>. Site created with <a href="//jekyllrb.com" target="_blank">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll" target="_blank">Tufte theme</a>. &copy; 2020
</div>
</footer>
  </body>
</html>

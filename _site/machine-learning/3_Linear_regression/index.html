<!DOCTYPE html>
<html>
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Linear Regression</title>
  <meta name="description" content="ISPeL is an interactive system for personalization of learning. It uses topic-based authoring.">

  <!---   <link rel="stylesheet" href="/ISPeL-content-machine-learning/css/tufte.css" --->
  <link rel="stylesheet" href="../../css/tufte.css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'><!-- Load up MathJax script if needed ... specify in /_data/options.yml file--><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');
  </script>

  <link rel="canonical" href="http://localhost:7000/ISPeL-content-machine-learning/machine-learning/3_Linear_regression/">
  <link rel="alternate" type="application/rss+xml" title="ISPeL-content-machine-learning" href="http://localhost:7000/ISPeL-content-machine-learning/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->


<header>
    <nav class="group">
    <a href="../../">Machine Learning</a>
    <a href="http://ispel.cs.ecu.edu/" _target="blank">ISPeL</a>
    <a href="http://seng5005.cs.ecu.edu/" _target="blank">Fall 2020</a>
    <a href="https://github.com/vngudivada/ISPeL-content-machine-learning.git" _target="blank">GitHub</a>
    </nav>
</header>

    <article class="group">
      

<h1>Linear regression</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        E: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Re: "{\\mathbb{R}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h3 id="simple-linear-regression-using-a-single-predictor-x">Simple linear regression using a single predictor X.</h3>

<ul>
  <li>We <span style="background-color: #FFFF00">assume a model</span></li>
</ul>

\[Y = \beta_0 + (\beta_1)X + \epsilon\]

<ul>
  <li>where \(\beta_0\) and \(\beta_1\) are two unknown constants that represent the <span style="background-color: #FFFF00">intercept</span> and <span style="background-color: #FFFF00">slope</span>, also known as <span style="background-color: #FFFF00">coefficients</span> or <span style="background-color: #FFFF00">parameters</span>, and \(\epsilon\) is the error term.</li>
  <li>
    <p>Given some \(\hat{\beta_0}\) and \(\hat{\beta_1}\) for the  model cofficients, we predict Y using  \(\hat{y} = \hat{\beta_0} + \hat{\beta_1}x,\)</p>
  </li>
  <li>where \(\hat{y}\) indicates a prediction of \(Y\) on the basis of \(X=x\)</li>
  <li>The hat symbol denotes an <span style="background-color: #FFFF00">estimated value</span>.</li>
</ul>

<h2 id="estimation-of-the-parameters-by-least-squares">Estimation of the parameters by least squares</h2>
<ul>
  <li>Let \(\hat{y} _i = \hat{ \beta }_0 +  \hat{ \beta }_ix_i\) be the prediction for Y based on the ith value of X. Then \(e_i =y_i - \hat{y}_i\) represents the ith <font color="green">residual</font></li>
  <li>We define the <span style="background-color: #FFFF00">residual sum of squares</span> (RSS) as
\(RSS = e_1^2 + e_2^2 +...+ e_n^2,\)
or equivalently as
\(RSS = (y_1- \hat{ \beta }_0 - \hat{ \beta }_ix_1)^2+(y_2 - \hat{ \beta }_0 - \hat{ \beta }_ix_2)^2+...+(y_n -\hat{ \beta }_0 - \hat{ \beta }_ix_n)^2\)</li>
  <li>
    <p>The least squared approach chooses \(\hat{\beta}_0\) and \(\hat{\beta}_1\) to minimize the RSS. The minimizing values can be shown to be \(\hat{ \beta} _1 = \frac{ \Sigma _{i=1}^n(x_i- \overline{x})(y_i- \overline{y})}{ \Sigma _{i=1}^n(x_i- \overline{x})^2}, \hat{ \beta_0} = \overline{ y }-  \hat{ \beta_1} \overline{x},\) where \(\overline{y} \equiv \frac{1}{n} \Sigma_{i=1}^ny_i\) and \(\overline{x} \equiv \frac{1}{n} \Sigma_{i=1}^nx_i\) are the <span style="background-color: #FFFF00"> sample means.</span></p>
  </li>
  <li>
    <p>Linear regression is a simple approach to supervised learning. It assumes that the dependence of Y on \(X_1,X_2,...X_p\) is linear.</p>
  </li>
  <li>
    <p>True regression functions are never linear!</p>
  </li>
  <li>Although it may seem overly simplistic, linear regression is extremely useful both conceptually and practically.</li>
</ul>

<h2 id="linear-regression-for-the-advertising-data">Linear regression for the advertising data</h2>
<h4 id="consider-the-advertising-data-shown">Consider the advertising data shown…</h4>
<p><img src="linreg1.png" alt="" /></p>
<h4 id="questions-we-might-ask">Questions we might ask:</h4>
<ul>
  <li>Is there a relationship between advertising budget and sales?</li>
  <li>How strong is the relationship between advertising budget and sales?</li>
  <li>Which media contributes to sales?</li>
  <li>How accurately can we predict future sales?</li>
  <li>Is the relationship linear?</li>
  <li>Is there synergy among the advertising media?</li>
  <li>Here is a possible way to build the linear model:</li>
  <li><img src="linreg0.png" alt="" /></li>
</ul>

<h3 id="group-activcity-5-linear-regression-from-scratch">Group Activcity 5: Linear Regression from Scratch</h3>
<ul>
  <li>Group Activity 5: <a href="https://github.com/ruiwu1990/CSCI_4120/blob/master/HW_linear_regression/HW_1.ipynb">https://github.com/ruiwu1990/CSCI_4120/blob/master/HW_linear_regression/HW_1.ipynb</a></li>
  <li>Finish to do section, you will have the linear regression implemtation from scratch.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td> </td>
      <td><a href="../../">Index</a></td>
      <td> </td>
      <td> </td>
      <td><a href="../">Prev</a></td>
      <td> </td>
      <td> </td>
      <td><a href="lin-reg2/">Next</a></td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>


    </article>
    <footer>
<hr class="slender">
<div class="credits">
This work is supported by the <a href="https://www.nsf.gov/" target="_blank">NSF</a> IUSE/PFE:RED award No. <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730568" target="_blank">1730568</a>. Site created with <a href="//jekyllrb.com" target="_blank">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll" target="_blank">Tufte theme</a>. &copy; 2020
</div>
</footer>
  </body>
</html>
